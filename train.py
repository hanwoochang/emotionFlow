#train.py
import json
import torch
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns 
from pathlib import Path
from tqdm import tqdm
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix 
from transformers import AutoTokenizer, TrainingArguments, Trainer, EarlyStoppingCallback
from sklearn.utils.class_weight import compute_class_weight
import numpy as np

# ê³µí†µ ëª¨ë“ˆ ì„í¬íŠ¸
from common import CONFIG, EMOTION_MAPPING, KRMediumWithMLP, EmotionDataset, set_korean_font

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ 
def load_emotion_data(folder_path, excluded_emotions=None):
    folder = Path(folder_path)
    json_files = list(folder.glob('*.json'))
    if not json_files:
        raise FileNotFoundError(f"'{folder_path}'ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    texts, emotions = [], []
    skipped_count = 0
    
    for file_path in tqdm(json_files, desc=f"ë¡œë”© {folder_path}"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            for unit in data.get('units', []):
                for script in unit.get('story_scripts', []):
                    content = script.get('content')
                    raw_emotion = script.get('emotion')
                    
                    if isinstance(raw_emotion, list):
                        raw_emotion = raw_emotion[0] if raw_emotion else None
                        
                    if content and raw_emotion:
                        mapped_emotion = EMOTION_MAPPING.get(raw_emotion)
                        if mapped_emotion and mapped_emotion not in (excluded_emotions or []):
                            texts.append(content)
                            emotions.append(mapped_emotion)
                        else:
                            skipped_count += 1
        except Exception as e:
            print(f"âš ï¸ {file_path.name} ì½ê¸° ì‹¤íŒ¨: {e}")
    
    print(f"âœ“ ì´ {len(texts)}ê°œ ìƒ˜í”Œ ë¡œë“œ, {skipped_count}ê°œ ì œì™¸ë¨")
    return texts, emotions

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)
    acc = accuracy_score(labels, preds)
    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}

# í•™ìŠµ ê·¸ë˜í”„ + í˜¼ë™ í–‰ë ¬ì„ í•¨ê»˜ ê·¸ë¦¬ëŠ” í•¨ìˆ˜
def plot_training_results(history, output_dir, y_true, y_pred, classes):
    set_korean_font()
    print("\nğŸ“Š í†µí•© ê²°ê³¼ ì‹œê°í™” ì¤‘ (Loss, Score, Matrix)...")
    
    train_loss = [x['loss'] for x in history if 'loss' in x]
    train_steps = [x['step'] for x in history if 'loss' in x]
    
    eval_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]
    eval_steps = [x['step'] for x in history if 'eval_loss' in x]
    eval_acc = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]
    eval_f1 = [x['eval_f1'] for x in history if 'eval_f1' in x]  

    # 1í–‰ 3ì—´ ê·¸ë˜í”„ ìƒì„±
    fig = plt.figure(figsize=(20, 6))
    
    # [1] Loss ë³€í™”
    plt.subplot(1, 3, 1)
    plt.plot(train_steps, train_loss, label='Train Loss', alpha=0.6, color='salmon')
    plt.plot(eval_steps, eval_loss, label='Validation Loss', marker='o', color='steelblue')
    plt.title('Loss ë³€í™” (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)')
    plt.xlabel('Steps')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # [2] ì„±ëŠ¥ ì§€í‘œ (Accuracy & F1)
    plt.subplot(1, 3, 2)
    if eval_acc: 
        plt.plot(eval_steps, eval_acc, label='Accuracy', marker='s', color='steelblue', linestyle='--')
    if eval_f1: 
        plt.plot(eval_steps, eval_f1, label='F1 Score', marker='^', color='darkorange', linewidth=2)
    plt.title('ì„±ëŠ¥ ì§€í‘œ ë³€í™” (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)')
    plt.xlabel('Steps')
    plt.ylabel('Score')
    plt.ylim(0, 1)
    plt.legend(loc='lower right')
    plt.grid(True, alpha=0.3)

    # [3] í˜¼ë™ í–‰ë ¬ (Confusion Matrix)
    plt.subplot(1, 3, 3)
    cm = confusion_matrix(y_true, y_pred)
    # ì •ê·œí™” (ë¹„ìœ¨ë¡œ í‘œì‹œ)
    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    
    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', 
                xticklabels=classes, yticklabels=classes, cbar=False)
    plt.title('ìµœì¢… ê²€ì¦ í˜¼ë™ í–‰ë ¬ (Confusion Matrix)')
    plt.xlabel('ì˜ˆì¸¡ê°’ (Predicted)')
    plt.ylabel('ì‹¤ì œê°’ (Actual)')
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    plt.tight_layout()
    plt.savefig(output_dir / 'training_result_summary.png')
    print(f"ğŸ’¾ ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {output_dir / 'training_result_summary.png'}")
    plt.show()

def balance_dataset(texts, labels, target_count=40000):
    df = pd.DataFrame({'text': texts, 'label': labels})
    
    balanced_dfs = []
    
    for label_class in df['label'].unique():
        sub_df = df[df['label'] == label_class]
        count = len(sub_df)
        
        if count > target_count:
            sampled = sub_df.sample(n=target_count, random_state=42)
            balanced_dfs.append(sampled)
        else:
            balanced_dfs.append(sub_df)
            
    final_df = pd.concat(balanced_dfs).sample(frac=1, random_state=42).reset_index(drop=True)
    
    print(f"\nâš–ï¸ ë°ì´í„° ë°¸ëŸ°ì‹± ì™„ë£Œ: ê° í´ë˜ìŠ¤ ìµœëŒ€ {target_count}ê°œë¡œ ì¡°ì •ë¨")
    print(final_df['label'].value_counts())
    
    return final_df['text'].tolist(), final_df['label'].tolist()

def main():
    print("\nğŸš€ ê°ì • ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘ \n")
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("Step 1. ë°ì´í„° ë¡œë“œ ì¤‘...")
    X_train_raw, y_train_text_raw = load_emotion_data('./train_data/label/', CONFIG['excluded_emotions'])
    X_val, y_val_text = load_emotion_data('./validation_data/label/', CONFIG['excluded_emotions'])

    # 2. ë°ì´í„° ë°¸ëŸ°ì‹±
    print("Step 2. ë°ì´í„° ë°¸ëŸ°ì‹± ì ìš© ì¤‘...")
    X_train, y_train_text = balance_dataset(X_train_raw, y_train_text_raw, target_count=40000)

    # 3. ë¼ë²¨ ì¸ì½”ë”©
    label_encoder = LabelEncoder()
    y_train = label_encoder.fit_transform(y_train_text)
    
    # Validation í•„í„°ë§ 
    valid_classes = set(label_encoder.classes_)
    X_val_filtered = []
    y_val_filtered_text = []
    for x, y in zip(X_val, y_val_text):
        if y in valid_classes:
            X_val_filtered.append(x)
            y_val_filtered_text.append(y)
            
    y_val = label_encoder.transform(y_val_filtered_text)
    num_labels = len(label_encoder.classes_)
    
    print(f"ğŸ·ï¸ ë¶„ë¥˜ í´ë˜ìŠ¤: {label_encoder.classes_}")

    # 4. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    class_weights = compute_class_weight(
        class_weight='balanced', 
        classes=np.unique(y_train), 
        y=y_train
    )
    print(f"âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights}")

    # 5. ëª¨ë¸ ì´ˆê¸°í™” 
    tokenizer = AutoTokenizer.from_pretrained(CONFIG['model_name'])
    model = KRMediumWithMLP(
        model_name=CONFIG['model_name'], 
        num_labels=num_labels,
        class_weights=class_weights 
    )

    # 6. ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = EmotionDataset(X_train, y_train, tokenizer, CONFIG['max_length'])
    val_dataset = EmotionDataset(X_val_filtered, y_val, tokenizer, CONFIG['max_length'])

    # 7. í•™ìŠµ ì„¤ì •
    training_args = TrainingArguments(
        output_dir=CONFIG['output_dir'],
        num_train_epochs=CONFIG['epochs'],
        per_device_train_batch_size=CONFIG['batch_size'],
        per_device_eval_batch_size=CONFIG['batch_size'],
        learning_rate=CONFIG['learning_rate'],
        weight_decay=0.1,        
        eval_strategy='epoch',
        save_strategy='epoch',
        load_best_model_at_end=True,
        metric_for_best_model='eval_loss',
        greater_is_better=False,
        logging_steps=50,
        save_total_limit=2,
        fp16=torch.cuda.is_available(),
        report_to='none',
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=compute_metrics,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]
    )
    
    # í•™ìŠµ ì‹œì‘
    trainer.train()

    print("\nğŸ í•™ìŠµ ì™„ë£Œ! ìµœì¢… ê²€ì¦ ë°ì´í„° í‰ê°€ ì¤‘...")
    predictions = trainer.predict(val_dataset)
    y_pred = np.argmax(predictions.predictions, axis=1)
    y_true = predictions.label_ids

    plot_training_results(
        trainer.state.log_history, 
        CONFIG['output_dir'],
        y_true, 
        y_pred, 
        label_encoder.classes_
    )

    output_path = Path(CONFIG['output_dir']) / 'final_model_mlp'
    output_path.mkdir(parents=True, exist_ok=True)
    
    torch.save(model.state_dict(), output_path / 'pytorch_model.bin')
    model.config.to_json_file(output_path / 'config.json')
    tokenizer.save_pretrained(output_path)
    
    with open(output_path / 'label_encoder.json', 'w', encoding='utf-8') as f:
        json.dump({'classes': label_encoder.classes_.tolist()}, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {output_path}")

if __name__ == "__main__":
    main()
