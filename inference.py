import json
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm
from torch.utils.data import DataLoader
from transformers import AutoTokenizer

# ê³µí†µ ëª¨ë“ˆ ì„í¬íŠ¸
from common import CONFIG, emotion_score_map, KRMediumWithMLP, EmotionDataset, set_korean_font

def find_movie_file_by_title(target_title, search_dir):
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬(search_dir)ì˜ json íŒŒì¼ë“¤ì„ ìˆœíšŒí•˜ë©°
    'title' ê°’ì´ target_titleê³¼ ì¼ì¹˜í•˜ëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    search_path = Path(search_dir)
    if not search_path.exists():
        print(f"âš ï¸ ê²½ê³ : ê²€ìƒ‰í•  í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {search_path}")
        return None

    print(f"ğŸ” '{target_title}' ì˜í™” íŒŒì¼ì„ ì°¾ëŠ” ì¤‘... (í´ë”: {search_path})")
    
    # í´ë” ë‚´ì˜ ëª¨ë“  .json íŒŒì¼ ê²€ìƒ‰
    for file_path in search_path.glob("*.json"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # JSON ë‚´ title í‚¤ í™•ì¸ (ê³µë°± ì œê±° í›„ ë¹„êµ)
                if 'title' in data and data['title'].strip() == target_title.strip():
                    return file_path
        except Exception as e:
            # íŒŒì¼ ì½ê¸° ì—ëŸ¬ ì‹œ ê±´ë„ˆëœ€
            continue
            
    return None

def load_model_and_predict(movie_path, model_dir):
    print(f"\nğŸ¬ ì˜í™” ê°ì • ë¶„ì„ ì‹œì‘: {movie_path}")
    model_dir = Path(model_dir)
    
    # 1. ë¼ë²¨ ì •ë³´ ë¡œë“œ
    with open(model_dir / 'label_encoder.json', 'r', encoding='utf-8') as f:
        label_data = json.load(f)
        id2label = {i: label for i, label in enumerate(label_data['classes'])}
        num_labels = len(label_data['classes'])
        
    # 2. ëª¨ë¸ ë¡œë“œ
    model = KRMediumWithMLP(CONFIG['model_name'], num_labels)
    try:
        model.load_state_dict(torch.load(model_dir / 'pytorch_model.bin'), strict=False)
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì¤‘ ê²½ê³ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.eval()
    
    # 3. ë°ì´í„° ë¡œë“œ
    with open(movie_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    texts = []
    # ë°ì´í„° êµ¬ì¡°ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§
    if 'units' in data:
        for unit in data.get('units', []):
            for script in unit.get('story_scripts', []):
                content = script.get('content')
                if content:
                    texts.append(content)
    elif 'text' in data:
        texts = data['text']
    
    if not texts:
        raise ValueError(f"ì˜í™” íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    print(f"ğŸ“ ì´ {len(texts)}ê°œ ì¥ë©´(ë¬¸ì¥) ë¶„ì„ ì¤‘...")
    
    # 4. ì¶”ë¡  ì‹¤í–‰
    dummy_labels = [0] * len(texts)
    pred_dataset = EmotionDataset(texts, dummy_labels, tokenizer, CONFIG['max_length'])
    pred_dataloader = DataLoader(pred_dataset, batch_size=CONFIG['analysis_batch_size'], shuffle=False)
    
    all_pred_ids = []
    
    with torch.no_grad():
        for batch in tqdm(pred_dataloader, desc="ê°ì •ì„ ì½ëŠ” ì¤‘"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            
            logits = model(input_ids, attention_mask=attention_mask)[0]
            pred_ids = torch.argmax(logits, dim=-1).cpu().numpy()
            all_pred_ids.extend(pred_ids)

    pred_emotions = [id2label[i] for i in all_pred_ids]
    return texts, pred_emotions

def analyze_emotion_shifts(predictions, texts, window_size=10, threshold=0.8):
    print(f"\nğŸ”„ ê°ì • ì „í™˜ì  ë¶„ì„ ì‹œì‘ (êµ¬ê°„: {window_size}, ì„ê³„ê°’: {threshold})")
    scores = np.array([emotion_score_map.get(e, 0) for e in predictions])
    n = len(scores)
    shift_points = []
    
    # ì´ë™ í‰ê·  ê³„ì‚°
    smoothed_scores = pd.Series(scores).rolling(window=window_size, min_periods=1).mean().values
    
    for i in range(window_size, n - window_size):
        prev_avg = np.mean(smoothed_scores[i - window_size:i])
        next_avg = np.mean(smoothed_scores[i:i + window_size])
        
        # ê°ì •ì˜ ë¶€í˜¸ê°€ ë°”ë€Œê³  ë³€í™”ëŸ‰ì´ í° ê²½ìš°
        change_magnitude = abs(next_avg - prev_avg)
        
        if (prev_avg * next_avg < 0 and change_magnitude >= threshold):
            shift_type = "ê¸ì •(í–‰ë³µ) â¡ï¸ ë¶€ì •(ìœ„ê¸°)" if prev_avg > next_avg else "ë¶€ì •(ìœ„ê¸°) â¡ï¸ ê¸ì •(í•´ì†Œ)"
            
            # ì¤‘ë³µ ë°©ì§€
            is_new = all(abs(p['index'] - i) >= window_size // 2 for p in shift_points)
            
            if is_new:
                shift_points.append({
                    'index': i, 
                    'type': shift_type,
                    'prev_score': float(prev_avg),
                    'next_score': float(next_avg),
                    'context': texts[i]
                })

    if shift_points:
        print(f"âœ… ì´ {len(shift_points)}ê°œì˜ ì£¼ìš” ê°ì • ì „í™˜ì  ë°œê²¬!")
        for p in shift_points:
            print(f"  ğŸš© ì¥ë©´ #{p['index']} [{p['type']}]")
            print(f"     ëŒ€ì‚¬: \"{p['context'][:40]}...\"")
            print(f"     ë³€í™”: {p['prev_score']:.2f} -> {p['next_score']:.2f}")
    else:
        print("íŠ¹ë³„í•œ ê°ì • ë°˜ì „ í¬ì¸íŠ¸ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    return shift_points

def plot_emotion_flow(predictions, title, output_dir):
    set_korean_font()
    scores = [emotion_score_map.get(e, 0) for e in predictions]
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    fig, axes = plt.subplots(1, 2, figsize=(20, 6))
    
    ax1 = axes[0]
    window_size = max(10, len(scores) // 20)
    smoothed = pd.Series(scores).rolling(window=window_size, center=True).mean()
    
    # ë°°ê²½ ìƒ‰ìƒ (ê¸ì •/ë¶€ì • ì˜ì—­)
    ax1.axhspan(0, 1.1, facecolor='green', alpha=0.05)
    ax1.axhspan(-1.1, 0, facecolor='red', alpha=0.05)
    
    ax1.plot(smoothed, color='steelblue', linewidth=2, label='ê°ì • íë¦„')
    ax1.fill_between(range(len(smoothed)), smoothed, alpha=0.3, color='steelblue')
    
    ax1.set_title(f"'{title}' ê°ì • íë¦„ (Time Series)", fontsize=15, fontweight='bold')
    ax1.set_xlabel("ì¥ë©´ ì§„í–‰ (Time)", fontsize=12)
    ax1.set_ylabel("ê°ì • ì ìˆ˜", fontsize=12)
    ax1.set_yticks([-1.0, -0.5, 0, 0.5, 1.0])
    ax1.set_yticklabels(['ê³µí¬/ë¶„ë…¸', 'ìŠ¬í””', 'ì¤‘ë¦½', 'ì•½í•œ ê¸ì •', 'ê¸°ì¨'])
    ax1.grid(True, alpha=0.3, linestyle='--')
    ax1.legend(loc='upper left')
    ax1.set_ylim(-1.2, 1.2)

    ax2 = axes[1]
    n = len(predictions)
    sections = {
        'ë„ì…ë¶€': (0, int(n*0.2)),
        'ì „ê°œ': (int(n*0.2), int(n*0.5)),
        'ìœ„ê¸°(ì ˆì •)': (int(n*0.5), int(n*0.8)),
        'ê²°ë§': (int(n*0.8), n)
    }
    
    labels = []
    avgs = []
    doms = []
    
    for name, (start, end) in sections.items():
        part = predictions[start:end]
        if not part: 
            avg_score = 0
            dominant = "ì—†ìŒ"
        else:
            avg_score = np.mean([emotion_score_map.get(e, 0) for e in part])
            emotion_power = {}
            for emo in part:
                score = abs(emotion_score_map.get(emo, 0))
                if score == 0: score = 0.1
                emotion_power[emo] = emotion_power.get(emo, 0) + score
            dominant = max(emotion_power, key=emotion_power.get) if emotion_power else "ì—†ìŒ"
            
        labels.append(name)
        avgs.append(avg_score)
        doms.append(dominant)

    # êº¾ì€ì„  (íë¦„ íŒŒì•…ìš©)
    ax2.plot(labels, avgs, marker='o', color='gray', linestyle='--', linewidth=1, alpha=0.5)
    
    # ë§‰ëŒ€ ê·¸ë˜í”„
    colors = ['red' if s < 0 else 'green' for s in avgs]
    bars = ax2.bar(labels, avgs, color=colors, alpha=0.6, width=0.5)
    
    # í…ìŠ¤íŠ¸ ë¼ë²¨
    for rect, dom, val in zip(bars, doms, avgs):
        height = rect.get_height()
        pos = height + 0.05 if height >= 0 else height - 0.15
        ax2.text(rect.get_x() + rect.get_width()/2.0, pos, 
                 f"{dom}\n({val:.2f})", ha='center', va='center', fontweight='bold', fontsize=11)

    ax2.set_title(f"'{title}' ê¸°ìŠ¹ì „ê²° êµ¬ê°„ ë¶„ì„", fontsize=15, fontweight='bold')
    ax2.axhline(0, color='black', linewidth=1)
    ax2.set_ylim(-1.2, 1.2)
    ax2.grid(axis='y', alpha=0.3, linestyle='--')

    plt.tight_layout()
    
    # íŒŒì¼ë¡œë„ ì €ì¥
    save_path = output_dir / f"{title}_combined_analysis.png"
    plt.savefig(save_path)
    print(f"ğŸ“Š ê·¸ë˜í”„ ì´ë¯¸ì§€ ì €ì¥ë¨: {save_path}")
    
    plt.show()

def save_results_to_json(texts, preds, title, output_dir):
    output_data = []
    for t, p in zip(texts, preds):
        output_data.append({
            'content': t,
            'emotion': p,
            'score': emotion_score_map.get(p, 0)
        })
    
    save_path = Path(output_dir) / f"{title}_analyzed_result.json"
    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨: {save_path}")

def main():
    model_path = Path(CONFIG['output_dir']) / 'final_model_mlp'
    output_dir = Path(CONFIG['output_dir'])
    
    test_data_dir = "./test" 
    
    if not model_path.exists():
        print(f"âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return

    # 1. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    while True:
        target_title = input("\nğŸ“½ï¸ ë¶„ì„í•  ì˜í™” ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ q ì…ë ¥): ").strip()
        
        if target_title.lower() == 'q':
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
        if not target_title:
            print("ì œëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue

        # 2. íŒŒì¼ ì°¾ê¸°
        found_file_path = find_movie_file_by_title(target_title, test_data_dir)
        
        if found_file_path:
            print(f"âœ… íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {found_file_path}")
            
            # 3. ì¶”ë¡  ë° ë¶„ì„ ì‹¤í–‰
            texts, preds = load_model_and_predict(found_file_path, model_path)
            
            # 4. ê²°ê³¼ ì €ì¥
            save_results_to_json(texts, preds, target_title, output_dir)
            
            # 5. ì‹œê°í™” (ìˆ˜ì •ë¨: í•œ ë²ˆ í˜¸ì¶œë¡œ í†µí•© ê·¸ë˜í”„ ìƒì„±)
            plot_emotion_flow(preds, target_title, output_dir)
            
            # 6. í…ìŠ¤íŠ¸ ì „í™˜ì  ë¶„ì„
            analyze_emotion_shifts(preds, texts, CONFIG['shift_window_size'], CONFIG['shift_threshold'])
            
            print(f"\nğŸ‰ '{target_title}' ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print(f"âŒ '{test_data_dir}' í´ë” ë‚´ì—ì„œ ì œëª©ì´ '{target_title}'ì¸ ì˜í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   (ë„ì–´ì“°ê¸°ê°€ ì •í™•í•œì§€, íŒŒì¼ì´ í•´ë‹¹ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”)")

if __name__ == "__main__":
    main()

