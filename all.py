import os, json, platform
from pathlib import Path
import numpy as np
import pandas as pd
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
from transformers import (
    AutoTokenizer, AutoModel, 
    TrainingArguments, Trainer, EarlyStoppingCallback
)
import matplotlib.pyplot as plt
from tqdm import tqdm
from sklearn.metrics import precision_recall_fscore_support, accuracy_score

# í•œê¸€ í°íŠ¸ ì„¤ì •
if platform.system() == 'Windows':
    plt.rc('font', family='Malgun Gothic')
elif platform.system() == 'Darwin':
    plt.rc('font', family='AppleGothic')
else:
    try:
        import matplotlib.font_manager as fm
        font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
        if os.path.exists(font_path):
            fm.fontManager.addfont(font_path)
            plt.rc('font', family='NanumGothic')
        else:
            pass
    except Exception:
        plt.rc('font', family='DejaVu Sans') 
        
plt.rcParams['axes.unicode_minus'] = False

# ì„¤ì • (Test Mode ê´€ë ¨ í•­ëª© ì œê±°ë¨)
CONFIG = {
    'model_name': 'snunlp/KR-Medium',
    'max_length': 128,
    'batch_size': 16,
    'epochs': 5,
    'learning_rate': 5e-5,
    'excluded_emotions': ['ë¯¸ë¶„ë¥˜'], 
    'output_dir': Path('./results'),
    'analyze_movie_path': './test/1121.json',
    'analysis_batch_size': 32,
    'shift_window_size': 10, # ê°ì • ì „í™˜ì  ë¶„ì„ì„ ìœ„í•œ ìœˆë„ìš° í¬ê¸°
    'shift_threshold': 0.5,  # ê°ì • ì „í™˜ì  íŒë‹¨ ì„ê³„ê°’ (ì´ì „ ëŒ€ë¹„ ë³€í™”ëŸ‰)
}

# 7ëŒ€ ëŒ€í‘œ ê°ì •ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë§¤í•‘ í…Œì´ë¸”
EMOTION_MAPPING = {
    # 1. ê¸°ì¨ (Positive)
    'ê¸°ì¨': 'ê¸°ì¨', 'í–‰ë³µ': 'ê¸°ì¨', 'ì„¤ë ˜': 'ê¸°ì¨', 'ë§Œì¡±': 'ê¸°ì¨', 
    'ì•ˆì •': 'ê¸°ì¨', 'ê³ ë§ˆì›€': 'ê¸°ì¨', 'ê¸°ëŒ€ê°': 'ê¸°ì¨', 'ëŠê¸‹': 'ê¸°ì¨', 
    'ì‚¬ë‘': 'ê¸°ì¨', 'ìì‹ ê° ìˆë‹¤': 'ê¸°ì¨', 'ì¬ë¯¸': 'ê¸°ì¨', 'ì¦ê±°ì›€': 'ê¸°ì¨', 
    'í¸ì•ˆí•¨': 'ê¸°ì¨', 'ì‹ ë¢°': 'ê¸°ì¨',
    
    # 2. ìŠ¬í”” (Sadness)
    'ìŠ¬í””': 'ìŠ¬í””', 'ìš°ìš¸': 'ìŠ¬í””', 'ìƒì‹¤ê°': 'ìŠ¬í””', 'ê´´ë¡œì›€': 'ìŠ¬í””', 
    'ì™¸ë¡œì›€': 'ìŠ¬í””', 'í˜ë“¦': 'ìŠ¬í””', 'ì§€ì¹¨': 'ìŠ¬í””', 'í”¼ê³¤': 'ìŠ¬í””', 
    'ì‹¤ë§': 'ìŠ¬í””', 'ì„œìš´í•˜ë‹¤': 'ìŠ¬í””', 'ë¯¸ì•ˆ': 'ìŠ¬í””', 'í›„íšŒí•˜ë‹¤': 'ìŠ¬í””', 
    'ë¶€ë„ëŸ¬ì›€': 'ìŠ¬í””', 'ì• ì²˜ë¡œìš´': 'ìŠ¬í””', 'ì‹¬ê°': 'ìŠ¬í””', 'í—ˆíƒˆí•¨': 'ìŠ¬í””',
    
    # 3. ë¶„ë…¸ (Anger)
    'ë¶„ë…¸': 'ë¶„ë…¸', 'í™”ë‚˜ë‹¤': 'ë¶„ë…¸', 'ì§œì¦': 'ë¶„ë…¸', 'ë¶ˆë§Œ': 'ë¶„ë…¸', 
    'ì–µìš¸í•¨': 'ë¶„ë…¸', 'ì§ˆíˆ¬': 'ë¶„ë…¸',
    
    # 4. ê³µí¬ (Fear/Anxiety)
    'ê³µí¬': 'ê³µí¬', 'ë‘ë ¤ì›€': 'ê³µí¬', 'ë¶ˆì•ˆ': 'ê³µí¬', 'ê±±ì •': 'ê³µí¬', 
    'ì´ˆì¡°': 'ê³µí¬', 'ì˜ì‹¬': 'ê³µí¬', 'í˜¼ë€': 'ê³µí¬', 'ì¡°ê¸‰í•¨': 'ê³µí¬',
    
    # 5. ë†€ëŒ (Surprise)
    'ë†€ëŒ': 'ë†€ëŒ', 'ë‹¹í™©': 'ë†€ëŒ', 'í™©ë‹¹': 'ë†€ëŒ', 'ì–´ì´ì—†ìŒ': 'ë†€ëŒ',
    
    # 6. í˜ì˜¤ (Disgust)
    'í˜ì˜¤': 'í˜ì˜¤', 'ë¶ˆì¾Œ': 'í˜ì˜¤', 'ì‹«ì¦': 'í˜ì˜¤',
    
    # 7. ì¤‘ë¦½ (Neutral)
    'ì¤‘ë¦½': 'ì¤‘ë¦½', 'ë‹´ë‹´í•˜ë‹¤': 'ì¤‘ë¦½', 'ë¬´ê´€ì‹¬': 'ì¤‘ë¦½', 'ì§€ë£¨í•¨': 'ì¤‘ë¦½', 
    'ì‹ ì¤‘': 'ì¤‘ë¦½', 'ê¶ê¸ˆí•¨': 'ì¤‘ë¦½'
}

# ìƒˆë¡œìš´ 7ê°œ ê°ì •ì˜ ì ìˆ˜ ë§µ
emotion_score_map = {
    'ê¸°ì¨': 1.0,
    'ì¤‘ë¦½': 0.0,
    'ë†€ëŒ': -0.1, 
    'ìŠ¬í””': -0.8,
    'ë¶„ë…¸': -0.9,
    'ê³µí¬': -1.0, 
    'í˜ì˜¤': -0.7
}

# ì»¤ìŠ¤í…€ ëª¨ë¸: KR-Medium + MLP ë¶„ë¥˜ê¸°
class KRMediumWithMLP(nn.Module):
    def __init__(self, model_name, num_labels):
        super().__init__()
        self.base_model = AutoModel.from_pretrained(model_name)
        self.num_labels = num_labels
        self.config = self.base_model.config
        classifier_dropout = (
            self.config.classifier_dropout if self.config.classifier_dropout is not None else self.config.hidden_dropout_prob
        )
        self.dropout = nn.Dropout(classifier_dropout)
        self.hidden_size = self.config.hidden_size
        
        self.mlp_head = nn.Sequential(
            nn.Linear(self.hidden_size, self.hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(self.hidden_size // 2, num_labels)
        )
        self.loss_fct = nn.CrossEntropyLoss()

    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):
        outputs = self.base_model(
            input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids,
            return_dict=True
        )
        
        pooled_output = outputs.pooler_output if outputs.pooler_output is not None else outputs.last_hidden_state[:, 0]
        pooled_output = self.dropout(pooled_output)
        
        logits = self.mlp_head(pooled_output)
        
        loss = None
        if labels is not None:
            loss = self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1))
        
        return (loss, logits) if loss is not None else (logits,)

def load_emotion_data(folder_path, excluded_emotions=None):
    folder = Path(folder_path)
    json_files = list(folder.glob('*.json'))
    if not json_files:
        raise FileNotFoundError(f"'{folder_path}'ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    texts, emotions = [], []
    skipped_count = 0
    
    for file_path in tqdm(json_files, desc=f"ë¡œë”© {folder_path}"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            for unit in data.get('units', []):
                for script in unit.get('story_scripts', []):
                    content = script.get('content')
                    raw_emotion = script.get('emotion') # ì›ë³¸ ê°ì •
                    
                    if isinstance(raw_emotion, list):
                        raw_emotion = raw_emotion[0] if raw_emotion else None
                        
                    if content and raw_emotion:
                        # ì›ë³¸ ê°ì •ì„ 7ëŒ€ ê°ì •ìœ¼ë¡œ ë³€í™˜
                        mapped_emotion = EMOTION_MAPPING.get(raw_emotion)
                        
                        # ë§¤í•‘ëœ ê°ì •ì´ ìˆê³ , ì œì™¸ ëª©ë¡ì— ì—†ìœ¼ë©´ ì¶”ê°€
                        if mapped_emotion and mapped_emotion not in (excluded_emotions or []):
                            texts.append(content)
                            emotions.append(mapped_emotion) # ë³€í™˜ëœ ë¼ë²¨ ì €ì¥
                        else:
                            skipped_count += 1
                            
        except Exception as e:
            print(f"âš ï¸ {file_path.name} ì½ê¸° ì‹¤íŒ¨: {e}")
    
    print(f"âœ“ ì´ {len(texts)}ê°œ ìƒ˜í”Œ ë¡œë“œ (7ëŒ€ ê°ì • ë³€í™˜ ì™„ë£Œ), {skipped_count}ê°œ ì œì™¸ë¨")
    return texts, emotions

class EmotionDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.encodings = tokenizer(
            texts, 
            truncation=True, 
            padding='max_length',
            max_length=max_length, 
            return_tensors='pt'
        )
        self.labels = torch.tensor(labels, dtype=torch.long) if labels is not None else None
    
    def __len__(self):
        return len(self.encodings['input_ids'])
    
    def __getitem__(self, idx):
        item = {k: v[idx] for k, v in self.encodings.items()}
        if self.labels is not None:
            item['labels'] = self.labels[idx]
        return item

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    
    # ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜ ê³„ì‚° (weighted: í´ë˜ìŠ¤ ë¶ˆê· í˜• ê³ ë ¤)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)
    acc = accuracy_score(labels, preds)
    
    return {
        'accuracy': acc,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }

def train_emotion_classifier():
    print("\nğŸš€ ê°ì • ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (MLP ë¶„ë¥˜ê¸° í¬í•¨)\n")
    
    X_train, y_train_text = load_emotion_data('./train_data/label/', CONFIG['excluded_emotions'])
    X_val, y_val_text = load_emotion_data('./validation_data/label/', CONFIG['excluded_emotions'])

    valid_emotions = set(y_train_text)
    X_val_filtered = [x for x, y in zip(X_val, y_val_text) if y in valid_emotions]
    y_val_filtered = [y for y in y_val_text if y in valid_emotions]
    
    # Validation ë°ì´í„°ê°€ ë¹„ì—ˆì„ ê²½ìš°ì˜ ì•ˆì „ì¥ì¹˜
    if not X_val_filtered:
        X_val_filtered, y_val_filtered = X_train[:100], y_train_text[:100]
    
    print(f"ğŸ“Š Train ìƒ˜í”Œ: {len(X_train)}, Validation ìƒ˜í”Œ: {len(X_val_filtered)}")
    
    label_encoder = LabelEncoder()
    y_train = label_encoder.fit_transform(y_train_text)
    y_val = label_encoder.transform(y_val_filtered)
    num_labels = len(label_encoder.classes_)
    
    emotion_dist = pd.Series(y_train_text).value_counts()
    print(f"\nğŸ“ˆ Train ê°ì • ë¶„í¬ :")
    for emotion, count in emotion_dist.head(10).items():
        print(f"   {emotion}: {count}ê°œ")
    
    tokenizer = AutoTokenizer.from_pretrained(CONFIG['model_name'])
    model = KRMediumWithMLP(
        model_name=CONFIG['model_name'], 
        num_labels=num_labels
    )

    train_dataset = EmotionDataset(X_train, y_train, tokenizer, CONFIG['max_length'])
    val_dataset = EmotionDataset(X_val_filtered, y_val, tokenizer, CONFIG['max_length'])

    training_args = TrainingArguments(
        output_dir=str(CONFIG['output_dir']),
        num_train_epochs=CONFIG['epochs'],
        per_device_train_batch_size=CONFIG['batch_size'],
        per_device_eval_batch_size=CONFIG['batch_size'],
        learning_rate=CONFIG['learning_rate'],
        eval_strategy='epoch',
        save_strategy='epoch',
        load_best_model_at_end=True,
        metric_for_best_model='eval_loss',
        greater_is_better=False,
        logging_steps=50,
        save_total_limit=2,
        fp16=torch.cuda.is_available(),
        report_to='none',
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=compute_metrics,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]
    )
    
    print("\nğŸ”¥ í•™ìŠµ ì‹œì‘...")
    trainer.train()

    plot_training_history(trainer.state.log_history, CONFIG['output_dir'])

    output_path = CONFIG['output_dir'] / 'final_model_mlp'
    output_path.mkdir(parents=True, exist_ok=True)
    
    torch.save(model.state_dict(), output_path / 'pytorch_model.bin')
    model.config.to_json_file(output_path / 'config.json')
    tokenizer.save_pretrained(output_path)
    
    with open(output_path / 'label_encoder.json', 'w', encoding='utf-8') as f:
        json.dump({'classes': label_encoder.classes_.tolist()}, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {output_path}")
    
    eval_result = trainer.evaluate()
    print(f"\nğŸ“Š ìµœì¢… Validation Accuracy: {eval_result['eval_accuracy']:.4f}")
    
    return output_path

def load_model_and_predict(movie_path, model_dir):
    print(f"\nğŸ¬ ì˜í™” ê°ì • ë¶„ì„: {movie_path}")
    
    with open(model_dir / 'label_encoder.json', 'r', encoding='utf-8') as f:
        label_data = json.load(f)
        id2label = {i: label for i, label in enumerate(label_data['classes'])}
        num_labels = len(label_data['classes'])
        
    model = KRMediumWithMLP(CONFIG['model_name'], num_labels)
    model.load_state_dict(torch.load(model_dir / 'pytorch_model.bin'))
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.eval()
    
    with open(movie_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    texts = data.get('text', [])
    
    if not texts:
        raise ValueError("ì˜í™” íŒŒì¼ì— 'text' í•„ë“œê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    
    print(f"ğŸ“ ì´ {len(texts)}ê°œ ì¥ë©´ ë¶„ì„ ì¤‘...")
    
    pred_dataset = EmotionDataset(texts, None, tokenizer, CONFIG['max_length'])
    pred_dataloader = DataLoader(pred_dataset, batch_size=CONFIG['analysis_batch_size'])
    
    all_pred_ids = []
    
    with torch.no_grad():
        for batch in tqdm(pred_dataloader, desc="ì˜ˆì¸¡"):
            inputs = {k: v.to(device) for k, v in batch.items()}
            outputs = model(**inputs) 
            logits = outputs[0]
            pred_ids = torch.argmax(logits, dim=-1).cpu().numpy()
            all_pred_ids.extend(pred_ids)

    pred_emotions = [id2label[i] for i in all_pred_ids]
    
    emotion_counts = pd.Series(pred_emotions).value_counts()
    print(f"\nğŸ“Š ì˜ˆì¸¡ëœ ê°ì • ë¶„í¬ (ìƒìœ„ 10ê°œ):")
    for emotion, count in emotion_counts.head(10).items():
        print(f"   {emotion}: {count}ê°œ ({count/len(pred_emotions)*100:.1f}%)")
    
    return texts, pred_emotions


def analyze_emotion_shifts(predictions, texts, window_size=10, threshold=0.8):
    """ê°ì • ì ìˆ˜ì˜ ê¸‰ê²©í•œ ë³€í™”(ì „í™˜ì )ë¥¼ ë¶„ì„"""
    print(f"\nğŸ”„ ê°ì • ì „í™˜ì  ë¶„ì„ ì‹œì‘ (ìœˆë„ìš° í¬ê¸°: {window_size}, ì„ê³„ê°’: {threshold})")
    
    scores = np.array([emotion_score_map.get(e, 0) for e in predictions])
    n = len(scores)
    
    shift_points = []
    
    # ì´ë™ í‰ê·  ê³„ì‚° (ê°ì • ë…¸ì´ì¦ˆ ì œê±°)
    smoothed_scores = pd.Series(scores).rolling(window=window_size, min_periods=1, center=False).mean().values
    
    # ì „í™˜ì  ì°¾ê¸°
    for i in range(window_size, n - window_size):
        # ìœˆë„ìš° í¬ê¸° ì´ì „ì˜ í‰ê· 
        prev_avg = np.mean(smoothed_scores[i - window_size:i])
        # ìœˆë„ìš° í¬ê¸° ì´í›„ì˜ í‰ê· 
        next_avg = np.mean(smoothed_scores[i:i + window_size])
        
        # ê°ì • ë³€í™”ëŸ‰ (ì ˆëŒ€ê°’ ë³€í™”)
        change_magnitude = abs(next_avg - prev_avg)
        
        # ê¸ì •/ë¶€ì • ê·¹ì„±ì´ ë°”ë€Œì—ˆëŠ”ì§€ í™•ì¸ (ì˜ˆ: ê¸ì • -> ë¶€ì •, ë˜ëŠ” ë¶€ì • -> ê¸ì •)
        # ì´ì „ í‰ê· ì´ ì¤‘ë¦½(0) ê·¼ì²˜ê°€ ì•„ë‹ˆë©´ì„œ ê·¹ì„±ì´ ë°”ë€Œê³ , ë³€í™”ëŸ‰ì´ ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°
        if (prev_avg * next_avg < 0 and change_magnitude >= threshold):
            
            shift_type = "ê¸ì • â¡ï¸ ë¶€ì •" if prev_avg > next_avg else "ë¶€ì • â¡ï¸ ê¸ì •"
            
            # ì´ë¯¸ ê°€ê¹Œìš´ ì§€ì (window_size/2 ì´ë‚´)ì— ì „í™˜ì ì´ ê¸°ë¡ë˜ì—ˆë‹¤ë©´ ê±´ë„ˆëœ€
            is_new_shift = True
            for existing_point in shift_points:
                if abs(existing_point['index'] - i) < window_size // 2:
                    is_new_shift = False
                    break
            
            if is_new_shift:
                shift_points.append({
                    'index': i,
                    'type': shift_type,
                    'prev_avg': f"{prev_avg:.2f}",
                    'next_avg': f"{next_avg:.2f}",
                    'context': texts[i]
                })

    if shift_points:
        print(f"âœ… ì´ {len(shift_points)}ê°œì˜ ì£¼ìš” ê°ì • ì „í™˜ì  ë°œê²¬:")
        for point in shift_points:
            print(f"   * ì¥ë©´ {point['index'] + 1} ({point['type']}): ê°ì • ë³€í™” ({point['prev_avg']} -> {point['next_avg']})")
            print(f"     > ì£¼ìš” ë¬¸ë§¥: '{point['context'][:30]}...'")
    else:
        print("ğŸ’¡ ì£¼ìš” ê°ì • ì „í™˜ì (ì„ê³„ê°’ ì´ìƒ)ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    return shift_points

def plot_training_history(history, output_dir):
    """í•™ìŠµ ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ Lossì™€ ì„±ëŠ¥ ì§€í‘œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤."""
    print("\nğŸ“Š í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ì¤‘...")
    
    train_loss = []
    train_steps = []
    eval_loss = []
    eval_steps = []
    
    eval_acc = []
    eval_prec = []
    eval_f1 = []
    
    # ë¡œê·¸ ë°ì´í„° ë¶„ë¦¬
    for log in history:
        if 'loss' in log:  # í•™ìŠµ ì†ì‹¤
            train_loss.append(log['loss'])
            train_steps.append(log['step'])
        if 'eval_loss' in log:  # ê²€ì¦ ì†ì‹¤ ë° ì§€í‘œ
            eval_loss.append(log['eval_loss'])
            eval_steps.append(log['step'])
            # ì§€í‘œê°€ ìˆìœ¼ë©´ ì €ì¥
            if 'eval_accuracy' in log: eval_acc.append(log['eval_accuracy'])
            if 'eval_precision' in log: eval_prec.append(log['eval_precision'])
            if 'eval_f1' in log: eval_f1.append(log['eval_f1'])
            
    plt.figure(figsize=(14, 6))
    
    # 1. Loss ê·¸ë˜í”„ (ì¢Œì¸¡)
    plt.subplot(1, 2, 1)
    plt.plot(train_steps, train_loss, label='Train Loss', alpha=0.6, color='salmon')
    plt.plot(eval_steps, eval_loss, label='Validation Loss', marker='o', color='steelblue')
    plt.title('Loss ë³€í™” (ì†ì‹¤ê°’)', fontsize=14)
    plt.xlabel('Steps')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 2. Metrics ê·¸ë˜í”„ (ìš°ì¸¡)
    plt.subplot(1, 2, 2)
    if eval_acc: plt.plot(eval_steps, eval_acc, label='Accuracy (ì •í™•ë„)', marker='s')
    if eval_prec: plt.plot(eval_steps, eval_prec, label='Precision (ì •ë°€ë„)', marker='^', linestyle='--')
    if eval_f1: plt.plot(eval_steps, eval_f1, label='F1 Score', marker='x', linestyle=':')
    
    plt.title('ì„±ëŠ¥ ì§€í‘œ ë³€í™”', fontsize=14)
    plt.xlabel('Steps')
    plt.ylabel('Score')
    plt.ylim(0, 1.05)  # 0~1 ì‚¬ì´ë¡œ ê³ ì •
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    save_path = output_dir / 'training_history.png'
    plt.savefig(save_path, dpi=150)
    print(f"ğŸ’¾ í•™ìŠµ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {save_path}")
    plt.show()


def plot_emotion_flow(predictions, title, mode='segment'):
    """
    ê°ì • íë¦„ ì‹œê°í™”
    """
    scores = [emotion_score_map.get(e, 0) for e in predictions]
    
    if mode == 'smooth':
        window_size = max(10, len(scores) // 20)
        smoothed = pd.Series(scores).rolling(window=window_size, center=True).mean()
        
        plt.figure(figsize=(12, 6))
        plt.plot(smoothed, color='steelblue', linewidth=2, label='ê°ì • íë¦„')
        plt.fill_between(range(len(smoothed)), smoothed, alpha=0.3, color='steelblue')
        plt.axhline(0, color='black', linestyle='--', alpha=0.3)
        
        n = len(scores)
        plt.axvline(n//3, color='gray', linestyle=':', alpha=0.5)
        plt.axvline(2*n//3, color='gray', linestyle=':', alpha=0.5)
        plt.title(f"'{title}' ê°ì • íë¦„ (ì´ë™í‰ê· )", fontsize=17, pad=20)
        plt.xlabel("ì¥ë©´ ìˆœì„œ", fontsize=13)
        plt.ylabel("ê°ì • ì ìˆ˜ (-1 ~ +1)", fontsize=13)
        plt.legend()
        
    else:
        n = len(predictions)
        
        indices_list = [
            (0, 1),                             # 1. ì²˜ìŒ (ë”± ì²« ë²ˆì§¸ ë¬¸ì¥)
            (0, int(n * 0.25)),                 # 2. ê¸° (0~25%)
            (int(n * 0.25), int(n * 0.5)),      # 3. ìŠ¹ (25~50%)
            (int(n * 0.5), int(n * 0.75)),      # 4. ì „ (50~75%)
            (int(n * 0.75), n),                 # 5. ê²° (75~100%)
            (n - 1, n)                          # 6. í›„ë°˜ (ë”± ë§ˆì§€ë§‰ ë¬¸ì¥)
        ]
        
        labels = ['ì²˜ìŒ(Start)', 'ê¸°', 'ìŠ¹', 'ì „', 'ê²°', 'ë§ˆì§€ë§‰(End)']
        
        parts = [predictions[start:end] for start, end in indices_list]

        def segment_stats(preds):
            """ê°€ì¤‘ì¹˜(ë¹ˆë„ * ê°•ë„)ê°€ ê°€ì¥ ë†’ì€ ê°ì •ì„ ëŒ€í‘œ ê°ì •ìœ¼ë¡œ ì„ ì •"""
            if not preds: return 0, "ì—†ìŒ"
            
            counts = pd.Series(preds).value_counts()
            names = counts.index
            frequencies = counts.values
            
            seg_scores = np.array([emotion_score_map.get(n, 0) for n in names])
            
            weights = frequencies * np.abs(seg_scores) + 1e-6
            weighted_avg = np.sum(seg_scores * weights) / np.sum(weights)
            
            max_weight_idx = np.argmax(weights)
            dominant = names[max_weight_idx]
            
            return weighted_avg, dominant
        
        segments, averages, dominants = [], [], []
        
        for name, part in zip(labels, parts):
            if len(part) > 0: 
                avg, dom = segment_stats(part)
                segments.append(name)
                averages.append(avg)
                dominants.append(dom)
        
        plt.figure(figsize=(12, 6))
        plt.plot(segments, averages, color='gray', linewidth=2, alpha=0.7, marker='o', markersize=8)
        
        for x, y, e in zip(segments, averages, dominants):
            color = 'salmon' if y < 0 else 'cornflowerblue'
            size = 22 if x in ['ì²˜ìŒ(Start)', 'ë§ˆì§€ë§‰(End)'] else 15
            
            plt.plot(x, y, 'o', color=color, markersize=size)
            
            v_offset = 0.1 if segments.index(x) % 2 == 0 else -0.15
            if y > 0.8: v_offset = -0.15 
            if y < -0.8: v_offset = 0.1
            
            plt.text(x, y + v_offset, f"{e}\n({y:.2f})", ha='center', fontsize=11, fontweight='bold', color='black')
        
        plt.axhline(0, color='black', linestyle='--', alpha=0.3)
        plt.title(f"'{title}' ìƒì„¸ ê°ì • íë¦„ (ì²«ì¥ë©´ vs ê¸°ìŠ¹ì „ê²° vs ëì¥ë©´)", fontsize=17, pad=20)
        plt.ylabel("ê°ì • ì ìˆ˜", fontsize=13)
        plt.ylim(-1.2, 1.2)
    
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    output_file = f"{title}_emotion_flow_{mode}_start_end.png"
    plt.savefig(output_file, dpi=150)
    print(f"\nğŸ’¾ ìƒì„¸ ê·¸ë˜í”„ ì €ì¥: {output_file}")
    plt.show()

def plot_both_flows(predictions, title, texts):
    """êµ¬ê°„ë³„ + ì´ë™í‰ê·  ë‘ ê°€ì§€ ëª¨ë‘ ìƒì„± ë° ì „í™˜ì  ë¶„ì„ ì‹¤í–‰"""
    print("\nğŸ“Š ê°ì • íë¦„ ì‹œê°í™” ì¤‘...")
    
    # 1. ë¬¸ë§¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ êµ¬ê°„ë³„ ë¶„ì„
    plot_emotion_flow(predictions, title, mode='segment')
    
    # 2. ì´ë™í‰ê·  ì‹œê°í™”
    plot_emotion_flow(predictions, title, mode='smooth')
    
    # 3. ê°ì • ì „í™˜ì  ë¶„ì„ ì‹¤í–‰
    analyze_emotion_shifts(
        predictions, 
        texts, 
        window_size=CONFIG['shift_window_size'], 
        threshold=CONFIG['shift_threshold']
    )

if __name__ == "__main__":
    try:
        # í•™ìŠµ
        model_path = train_emotion_classifier()
        
        # ë¶„ì„
        if model_path and Path(CONFIG['analyze_movie_path']).exists():
            texts, preds = load_model_and_predict(CONFIG['analyze_movie_path'], model_path)
            movie_title = Path(CONFIG['analyze_movie_path']).stem
            plot_both_flows(preds, movie_title, texts)
        else:
            print(f"âš ï¸ ë¶„ì„í•  ì˜í™” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {CONFIG['analyze_movie_path']}")
            
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()